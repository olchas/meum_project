{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import catboost\n",
    "import argparse\n",
    "import os\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "import GPyOpt\n",
    "import time\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_file, categories, frequency):\n",
    "\n",
    "    m3c_file = pd.ExcelFile(input_file)\n",
    "\n",
    "    sheet_name = 'M3' + frequency\n",
    "\n",
    "    m3c_month_df = m3c_file.parse(sheet_name)\n",
    "\n",
    "    # strip unnecessary spaces from 'Category' column\n",
    "    m3c_month_df['Category'] = m3c_month_df['Category'].apply(lambda x: x.strip())\n",
    "\n",
    "    return m3c_month_df[m3c_month_df['Category'].isin(categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_series_generator(data_df, test_data_size):\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    for _, row in data_df.iterrows():\n",
    "        series_size = row['N']\n",
    "        start_year = row.iloc[4]\n",
    "        start_month = row.iloc[5]\n",
    "        row = row.iloc[6:series_size+6]\n",
    "        date = None\n",
    "        if frequency == 'Year':\n",
    "            freq = 'A'\n",
    "        elif frequency == 'Month':\n",
    "            if start_year == 0 or start_year == '0':\n",
    "                start_year = 1976\n",
    "                start_month = 1\n",
    "            freq = 'M'\n",
    "        elif frequency == 'Quart':\n",
    "            freq = 'Q'\n",
    "        else:\n",
    "            date = range(series_size)\n",
    "        if not date:\n",
    "            date = pd.date_range('1/{}/{}'.format(start_month, start_year), periods=series_size, freq=freq)\n",
    "        row.index = date\n",
    "        \n",
    "        train_data = row.iloc[range(series_size - test_data_size)]\n",
    "        test_data = row.iloc[range(series_size - test_data_size, series_size)]\n",
    "        # normalise data to range [0, 1]\n",
    "        train_tmp = train_data.values.astype(np.float64).reshape(-1,1)\n",
    "        test_tmp = test_data.values.astype(np.float64).reshape(-1, 1)\n",
    "        scaler.fit(train_tmp)\n",
    "        train_data = pd.Series([el[0] for el in scaler.transform(train_tmp).tolist()],  index = train_data.index)\n",
    "        test_data = pd.Series([el[0] for el in scaler.transform(test_tmp).tolist()],  index = test_data.index)\n",
    "\n",
    "        yield train_data, test_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    features = pd.DataFrame()\n",
    "    if frequency == 'Other':\n",
    "        features['index'] = df.index\n",
    "        return features\n",
    "    features['Year'] = df.index.year\n",
    "    if frequency == 'Month':\n",
    "        features['Month'] = df.index.month\n",
    "        features['Quarter'] = df.index.quarter\n",
    "    elif frequency == 'Quart':\n",
    "        features['Quarter'] = df.index.quarter\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cross_validation(model, train_data):\n",
    "    \"\"\"Perform cross validation of time series and return mean of rmse of all models created for validation\"\"\"\n",
    "    fold_nr = 0\n",
    "    rmse_per_fold = []\n",
    "    max_nr_of_folds = 6\n",
    "    train_data_size = len(train_data)\n",
    "\n",
    "    # set window_size so that max_nr_of_folds validations can be done\n",
    "    # and model is fitted on at least half of train data\n",
    "    window_size = int(train_data_size / 2 / max_nr_of_folds) or 1\n",
    "    window_slide = window_size\n",
    "\n",
    "    while fold_nr < max_nr_of_folds:\n",
    "        index = train_data_size - window_size - window_slide * fold_nr\n",
    "        # at least as much fit data as window_size\n",
    "        if index < window_size:\n",
    "            break\n",
    "        fit_data = train_data.iloc[:index]\n",
    "        validation_data = train_data.iloc[index:index + window_size]\n",
    "        model = fit_model(model, fit_data)\n",
    "\n",
    "        validation_forecast = model.predict(extract_features(validation_data))\n",
    "        rmse_per_fold.append(sqrt(mean_squared_error(validation_data.values, validation_forecast)))\n",
    "        fold_nr += 1\n",
    "    return mean(rmse_per_fold), model\n",
    "\n",
    "def fit_model(model, fit_data):\n",
    "    model = model.fit(extract_features(fit_data), fit_data.values, verbose=None, logging_level='Silent')\n",
    "    return model\n",
    "\n",
    "def make_prediction(model, train_data, test_data):\n",
    "    # prediction of train data\n",
    "    prediction = model.predict(list(range(len(train_data))))\n",
    "    # prediction of test data\n",
    "    forecast = model.predict(list(range(len(test_data))))\n",
    "    return [list(prediction), list(forecast)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [\n",
    "    {'name': 'learning_rate', 'type': 'continuous', 'domain': (0.01, 0.8)},\n",
    "    {'name': 'max_depth', 'type': 'discrete', 'domain': (2, 10)},\n",
    "    {'name': 'colsample_bylevel', 'type': 'continuous', 'domain': (0.5, 1.0)},\n",
    "    {'name': 'bagging_temperature', 'type': 'continuous', 'domain': (0.0, 100.0)},\n",
    "    {'name': 'random_strength', 'type': 'continuous', 'domain': (0.0, 100.0)},\n",
    "    {'name': 'reg_lambda', 'type': 'continuous', 'domain': (1.0, 100.0)},\n",
    "]\n",
    "\n",
    "def find_parameters(train_data):\n",
    "    def f(x):\n",
    "        model = catboost.CatBoostRegressor(\n",
    "            iterations=300,\n",
    "            **{el['name']: float(x[:, n]) if el['type'] == 'continuous' else int(x[:,n]) for n, el in enumerate(bounds)}\n",
    "        )\n",
    "        score, model = time_series_cross_validation(model, train_data=train_data)\n",
    "        return -score\n",
    "    \n",
    "    myBopt = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds)\n",
    "    myBopt.run_optimization(max_iter=5)\n",
    "    \n",
    "    return myBopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for frequency in ['Year', 'Month','Quart', 'Other']:\n",
    "    for category in ['MICRO', 'INDUSTRY', 'MACRO', 'FINANCE', 'DEMOGRAPHIC', 'OTHER']:\n",
    "        times.append((frequency, category, 'start', time.time()))\n",
    "        dfa = load_data('data/M3C.xls', [category], frequency)\n",
    "        if frequency == 'Year':\n",
    "            test_data_size = 6\n",
    "        elif frequency == 'Quart':\n",
    "            test_data_size = 8\n",
    "        elif frequency == 'Month':\n",
    "            test_data_size = 18\n",
    "        else:\n",
    "            test_data_size = 8\n",
    "\n",
    "        predicted_data_matrix = []\n",
    "        expected_data_matrix = []\n",
    "\n",
    "        normalized_forecast_data_matrix = []\n",
    "        normalized_test_data_matrix = []\n",
    "\n",
    "        # list of dicts of parameters of each trained model\n",
    "        parameters_dicts = []\n",
    "\n",
    "        rmse_prediction = []\n",
    "        rmse_forecast = []\n",
    "        rmse_total = []\n",
    "        print(times[-1])\n",
    "        for n, (train_data, test_data, scaler) in enumerate(next_series_generator(dfa, test_data_size)):\n",
    "            myopt = find_parameters(train_data)\n",
    "            model = catboost.CatBoostRegressor(**{el['name']: \n",
    "                                                  float(myopt.x_opt[n]) if el['type'] == 'continuous' \n",
    "                                                                        else int(myopt.x_opt[n]) \n",
    "                                                  for n, el in enumerate(bounds)})\n",
    "            model = fit_model(model, train_data)\n",
    "            prediction, forecast = model.predict(extract_features(train_data)), model.predict(extract_features(test_data))\n",
    "            parameters_dicts.append(model.get_params())\n",
    "#             print forecast\n",
    "            predicted_data = scaler.inverse_transform([list(prediction) + list(forecast)]).tolist()[0]\n",
    "            expected_data = scaler.inverse_transform([list(train_data) + list(test_data)]).tolist()[0]\n",
    "\n",
    "            rmse_prediction.append(sqrt(mean_squared_error(train_data, prediction)))\n",
    "            rmse_forecast.append(sqrt(mean_squared_error(test_data, forecast)))\n",
    "            rmse_total.append(sqrt(mean_squared_error(list(train_data) + list(test_data), list(prediction) + list(forecast))))\n",
    "\n",
    "            normalized_forecast_data_matrix.append(forecast)\n",
    "            normalized_test_data_matrix.append(test_data.values)\n",
    "\n",
    "            predicted_data_matrix.append(predicted_data)\n",
    "            expected_data_matrix.append(expected_data)\n",
    "        if not predicted_data_matrix:\n",
    "            continue\n",
    "            \n",
    "        times.append((frequency, category, 'stop', time.time()))\n",
    "        data_columns = list(range(1, max(len(x) for x in predicted_data_matrix) + 1))\n",
    "        series_index = list(range(len(predicted_data_matrix)))\n",
    "        series_length = [len(x) for x in predicted_data_matrix]\n",
    "\n",
    "        predicted_data_df = pd.DataFrame(predicted_data_matrix, columns=data_columns)\n",
    "        predicted_data_df['series'] = series_index\n",
    "        predicted_data_df['N'] = series_length\n",
    "        predicted_data_df['NF'] = test_data_size\n",
    "\n",
    "        # take parameters names from first dict\n",
    "        parameters_names = list(parameters_dicts[0].keys())\n",
    "        for parameter in parameters_names:\n",
    "            predicted_data_df[parameter] = [x[parameter] for x in parameters_dicts]\n",
    "\n",
    "        predicted_data_df['rmse_prediction'] = rmse_prediction\n",
    "        predicted_data_df['rmse_forecast'] = rmse_forecast\n",
    "        predicted_data_df['rmse_total'] = rmse_total\n",
    "\n",
    "        # change the order of columns\n",
    "        output_columns = ['series', 'N', 'NF'] + parameters_names + ['rmse_prediction', 'rmse_forecast', 'rmse_total'] \\\n",
    "                         + data_columns\n",
    "        predicted_data_df = predicted_data_df[output_columns]\n",
    "\n",
    "        expected_data_df = pd.DataFrame(expected_data_matrix, columns=data_columns)\n",
    "        expected_data_df['series'] = series_index\n",
    "        expected_data_df['N'] = series_length\n",
    "        expected_data_df['NF'] = test_data_size\n",
    "\n",
    "        output_columns = ['series', 'N', 'NF'] + data_columns\n",
    "        expected_data_df = expected_data_df[output_columns]\n",
    "\n",
    "        # calculate error separately for each month of forecast\n",
    "        rmse_per_month = []\n",
    "        for i in range(test_data_size):\n",
    "            month_forecast = [x[i] for x in normalized_forecast_data_matrix]\n",
    "            month_expected = [x[i] for x in normalized_test_data_matrix]\n",
    "            rmse_per_month.append(sqrt(mean_squared_error(month_expected, month_forecast)))\n",
    "\n",
    "        # calculate total error of all forecasts\n",
    "        all_forecast = list(chain(*normalized_forecast_data_matrix))\n",
    "        all_test = list(chain(*normalized_test_data_matrix))\n",
    "        total_rmse = sqrt(mean_squared_error(all_test, all_forecast))\n",
    "\n",
    "        output_dir = '{frequency}_{category}'.format(frequency=frequency, category=category)\n",
    "        if not os.path.isdir(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        normalized_forecast_data_df = pd.DataFrame(normalized_forecast_data_matrix)\n",
    "        normalized_test_dat_df = pd.DataFrame(normalized_test_data_matrix)\n",
    "\n",
    "        normalized_forecast_data_df.to_csv(os.path.join(output_dir, 'normalized_forecast.tsv'), sep='\\t', index=False)\n",
    "        normalized_test_dat_df.to_csv(os.path.join(output_dir, 'normalized_test_data.tsv'), sep='\\t', index=False)\n",
    "\n",
    "        predicted_data_df.to_csv(os.path.join(output_dir, 'predictions.tsv'), sep='\\t', index=False)\n",
    "        expected_data_df.to_csv(os.path.join(output_dir, 'expected.tsv'), sep='\\t', index=False)\n",
    "\n",
    "        with open(os.path.join(output_dir, 'rmse_file.tsv'), 'w') as f:\n",
    "            f.write('\\t'.join([str(x) for x in rmse_per_month]))\n",
    "            f.write('\\n' + str(total_rmse))\n",
    "times"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
