{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import catboost\n",
    "import argparse\n",
    "import os\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "import GPyOpt\n",
    "import time\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_file, categories, frequency):\n",
    "\n",
    "    m3c_file = pd.ExcelFile(input_file)\n",
    "\n",
    "    sheet_name = 'M3' + frequency\n",
    "\n",
    "    m3c_month_df = m3c_file.parse(sheet_name)\n",
    "\n",
    "    # strip unnecessary spaces from 'Category' column\n",
    "    m3c_month_df['Category'] = m3c_month_df['Category'].apply(lambda x: x.strip())\n",
    "\n",
    "    return m3c_month_df[m3c_month_df['Category'].isin(categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_series_generator(data_df, test_data_size):\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    for _, row in data_df.iterrows():\n",
    "        series_size = row['N']\n",
    "        start_year = row.iloc[4]\n",
    "        start_month = row.iloc[5]\n",
    "        row = row.iloc[6:series_size+6]\n",
    "        date = None\n",
    "        if frequency == 'Year':\n",
    "            freq = 'A'\n",
    "        elif frequency == 'Month':\n",
    "            if start_year == 0 or start_year == '0':\n",
    "                start_year = 1976\n",
    "                start_month = 1\n",
    "            freq = 'M'\n",
    "        elif frequency == 'Quart':\n",
    "            freq = 'Q'\n",
    "        else:\n",
    "            date = range(series_size)\n",
    "        if not date:\n",
    "            date = pd.date_range('1/{}/{}'.format(start_month, start_year), periods=series_size, freq=freq)\n",
    "        row.index = date\n",
    "        \n",
    "        train_data = row.iloc[range(series_size - test_data_size)]\n",
    "        test_data = row.iloc[range(series_size - test_data_size, series_size)]\n",
    "        # normalise data to range [0, 1]\n",
    "        train_tmp = train_data.values.astype(np.float64).reshape(-1,1)\n",
    "        test_tmp = test_data.values.astype(np.float64).reshape(-1, 1)\n",
    "        scaler.fit(train_tmp)\n",
    "        train_data = pd.Series([el[0] for el in scaler.transform(train_tmp).tolist()],  index = train_data.index)\n",
    "        test_data = pd.Series([el[0] for el in scaler.transform(test_tmp).tolist()],  index = test_data.index)\n",
    "\n",
    "        yield train_data, test_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    features = pd.DataFrame()\n",
    "    if frequency == 'Other':\n",
    "        features['index'] = df.index\n",
    "        return features\n",
    "    features['Year'] = df.index.year\n",
    "    if frequency == 'Month':\n",
    "        features['Month'] = df.index.month\n",
    "        features['Quarter'] = df.index.quarter\n",
    "    elif frequency == 'Quart':\n",
    "        features['Quarter'] = df.index.quarter\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cross_validation(model, train_data):\n",
    "    \"\"\"Perform cross validation of time series and return mean of rmse of all models created for validation\"\"\"\n",
    "    fold_nr = 0\n",
    "    rmse_per_fold = []\n",
    "    max_nr_of_folds = 6\n",
    "    train_data_size = len(train_data)\n",
    "\n",
    "    # set window_size so that max_nr_of_folds validations can be done\n",
    "    # and model is fitted on at least half of train data\n",
    "    window_size = int(train_data_size / 2 / max_nr_of_folds) or 1\n",
    "    window_slide = window_size\n",
    "\n",
    "    while fold_nr < max_nr_of_folds:\n",
    "        index = train_data_size - window_size - window_slide * fold_nr\n",
    "        # at least as much fit data as window_size\n",
    "        if index < window_size:\n",
    "            break\n",
    "        fit_data = train_data.iloc[:index]\n",
    "        validation_data = train_data.iloc[index:index + window_size]\n",
    "        model = fit_model(model, fit_data)\n",
    "\n",
    "        validation_forecast = model.predict(extract_features(validation_data))\n",
    "        rmse_per_fold.append(sqrt(mean_squared_error(validation_data.values, validation_forecast)))\n",
    "        fold_nr += 1\n",
    "    return mean(rmse_per_fold), model\n",
    "\n",
    "def fit_model(model, fit_data):\n",
    "    model = model.fit(extract_features(fit_data), fit_data.values, verbose=None, logging_level='Silent')\n",
    "    return model\n",
    "\n",
    "def make_prediction(model, train_data, test_data):\n",
    "    # prediction of train data\n",
    "    prediction = model.predict(list(range(len(train_data))))\n",
    "    # prediction of test data\n",
    "    forecast = model.predict(list(range(len(test_data))))\n",
    "    return [list(prediction), list(forecast)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [\n",
    "    {'name': 'learning_rate', 'type': 'continuous', 'domain': (0.01, 0.8)},\n",
    "    {'name': 'max_depth', 'type': 'discrete', 'domain': (2, 10)},\n",
    "    {'name': 'colsample_bylevel', 'type': 'continuous', 'domain': (0.5, 1.0)},\n",
    "    {'name': 'bagging_temperature', 'type': 'continuous', 'domain': (0.0, 100.0)},\n",
    "    {'name': 'random_strength', 'type': 'continuous', 'domain': (0.0, 100.0)},\n",
    "    {'name': 'reg_lambda', 'type': 'continuous', 'domain': (1.0, 100.0)},\n",
    "]\n",
    "\n",
    "def find_parameters(train_data):\n",
    "    def f(x):\n",
    "        model = catboost.CatBoostRegressor(\n",
    "            iterations=300,\n",
    "            **{el['name']: float(x[:, n]) if el['type'] == 'continuous' else int(x[:,n]) for n, el in enumerate(bounds)}\n",
    "        )\n",
    "        score, model = time_series_cross_validation(model, train_data=train_data)\n",
    "        return -score\n",
    "    \n",
    "    myBopt = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds)\n",
    "    myBopt.run_optimization(max_iter=5)\n",
    "    \n",
    "    return myBopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Year', 'MICRO', 'start', 1547967727.735799)\n",
      "('Year', 'INDUSTRY', 'start', 1547969849.659371)\n",
      "('Year', 'MACRO', 'start', 1547971486.521142)\n",
      "('Year', 'FINANCE', 'start', 1547972730.321985)\n",
      "('Year', 'DEMOGRAPHIC', 'start', 1547973604.17239)\n",
      "('Year', 'OTHER', 'start', 1547977321.535998)\n",
      "('Month', 'MICRO', 'start', 1547977504.226552)\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for frequency in ['Year', 'Month','Quart', 'Other']:\n",
    "    for category in ['MICRO', 'INDUSTRY', 'MACRO', 'FINANCE', 'DEMOGRAPHIC', 'OTHER']:\n",
    "        times.append((frequency, category, 'start', time.time()))\n",
    "        dfa = load_data('data/M3C.xls', [category], frequency)\n",
    "        if frequency == 'Year':\n",
    "            test_data_size = 6\n",
    "        elif frequency == 'Quart':\n",
    "            test_data_size = 8\n",
    "        elif frequency == 'Month':\n",
    "            test_data_size = 18\n",
    "        else:\n",
    "            test_data_size = 8\n",
    "\n",
    "        predicted_data_matrix = []\n",
    "        expected_data_matrix = []\n",
    "\n",
    "        normalized_forecast_data_matrix = []\n",
    "        normalized_test_data_matrix = []\n",
    "\n",
    "        # list of dicts of parameters of each trained model\n",
    "        parameters_dicts = []\n",
    "\n",
    "        rmse_prediction = []\n",
    "        rmse_forecast = []\n",
    "        rmse_total = []\n",
    "        print(times[-1])\n",
    "        for n, (train_data, test_data, scaler) in enumerate(next_series_generator(dfa, test_data_size)):\n",
    "            myopt = find_parameters(train_data)\n",
    "            model = catboost.CatBoostRegressor(**{el['name']: \n",
    "                                                  float(myopt.x_opt[n]) if el['type'] == 'continuous' \n",
    "                                                                        else int(myopt.x_opt[n]) \n",
    "                                                  for n, el in enumerate(bounds)})\n",
    "            model = fit_model(model, train_data)\n",
    "            prediction, forecast = model.predict(extract_features(train_data)), model.predict(extract_features(test_data))\n",
    "            parameters_dicts.append(model.get_params())\n",
    "#             print forecast\n",
    "            predicted_data = scaler.inverse_transform([list(prediction) + list(forecast)]).tolist()[0]\n",
    "            expected_data = scaler.inverse_transform([list(train_data) + list(test_data)]).tolist()[0]\n",
    "\n",
    "            rmse_prediction.append(sqrt(mean_squared_error(train_data, prediction)))\n",
    "            rmse_forecast.append(sqrt(mean_squared_error(test_data, forecast)))\n",
    "            rmse_total.append(sqrt(mean_squared_error(list(train_data) + list(test_data), list(prediction) + list(forecast))))\n",
    "\n",
    "            normalized_forecast_data_matrix.append(forecast)\n",
    "            normalized_test_data_matrix.append(test_data.values)\n",
    "\n",
    "            predicted_data_matrix.append(predicted_data)\n",
    "            expected_data_matrix.append(expected_data)\n",
    "        if not predicted_data_matrix:\n",
    "            continue\n",
    "            \n",
    "        times.append((frequency, category, 'stop', time.time()))\n",
    "        data_columns = list(range(1, max(len(x) for x in predicted_data_matrix) + 1))\n",
    "        series_index = list(range(len(predicted_data_matrix)))\n",
    "        series_length = [len(x) for x in predicted_data_matrix]\n",
    "\n",
    "        predicted_data_df = pd.DataFrame(predicted_data_matrix, columns=data_columns)\n",
    "        predicted_data_df['series'] = series_index\n",
    "        predicted_data_df['N'] = series_length\n",
    "        predicted_data_df['NF'] = test_data_size\n",
    "\n",
    "        # take parameters names from first dict\n",
    "        parameters_names = list(parameters_dicts[0].keys())\n",
    "        for parameter in parameters_names:\n",
    "            predicted_data_df[parameter] = [x[parameter] for x in parameters_dicts]\n",
    "\n",
    "        predicted_data_df['rmse_prediction'] = rmse_prediction\n",
    "        predicted_data_df['rmse_forecast'] = rmse_forecast\n",
    "        predicted_data_df['rmse_total'] = rmse_total\n",
    "\n",
    "        # change the order of columns\n",
    "        output_columns = ['series', 'N', 'NF'] + parameters_names + ['rmse_prediction', 'rmse_forecast', 'rmse_total'] \\\n",
    "                         + data_columns\n",
    "        predicted_data_df = predicted_data_df[output_columns]\n",
    "\n",
    "        expected_data_df = pd.DataFrame(expected_data_matrix, columns=data_columns)\n",
    "        expected_data_df['series'] = series_index\n",
    "        expected_data_df['N'] = series_length\n",
    "        expected_data_df['NF'] = test_data_size\n",
    "\n",
    "        output_columns = ['series', 'N', 'NF'] + data_columns\n",
    "        expected_data_df = expected_data_df[output_columns]\n",
    "\n",
    "        # calculate error separately for each month of forecast\n",
    "        rmse_per_month = []\n",
    "        for i in range(test_data_size):\n",
    "            month_forecast = [x[i] for x in normalized_forecast_data_matrix]\n",
    "            month_expected = [x[i] for x in normalized_test_data_matrix]\n",
    "            rmse_per_month.append(sqrt(mean_squared_error(month_expected, month_forecast)))\n",
    "\n",
    "        # calculate total error of all forecasts\n",
    "        all_forecast = list(chain(*normalized_forecast_data_matrix))\n",
    "        all_test = list(chain(*normalized_test_data_matrix))\n",
    "        total_rmse = sqrt(mean_squared_error(all_test, all_forecast))\n",
    "\n",
    "        output_dir = '{frequency}_{category}'.format(frequency=frequency, category=category)\n",
    "        if not os.path.isdir(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        normalized_forecast_data_df = pd.DataFrame(normalized_forecast_data_matrix)\n",
    "        normalized_test_dat_df = pd.DataFrame(normalized_test_data_matrix)\n",
    "\n",
    "        normalized_forecast_data_df.to_csv(os.path.join(output_dir, 'normalized_forecast.tsv'), sep='\\t', index=False)\n",
    "        normalized_test_dat_df.to_csv(os.path.join(output_dir, 'normalized_test_data.tsv'), sep='\\t', index=False)\n",
    "\n",
    "        predicted_data_df.to_csv(os.path.join(output_dir, 'predictions.tsv'), sep='\\t', index=False)\n",
    "        expected_data_df.to_csv(os.path.join(output_dir, 'expected.tsv'), sep='\\t', index=False)\n",
    "\n",
    "        with open(os.path.join(output_dir, 'rmse_file.tsv'), 'w') as f:\n",
    "            f.write('\\t'.join([str(x) for x in rmse_per_month]))\n",
    "            f.write('\\n' + str(total_rmse))\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1107916513401046,\n",
       " 1.3057029824864315,\n",
       " 1.4853428020208543,\n",
       " 1.7293992237878255,\n",
       " 1.8685093573353553,\n",
       " 2.0557236264272474,\n",
       " 0.7008160743895699,\n",
       " 0.9030964808511384,\n",
       " 0.7687930952553641,\n",
       " 0.7665422005247087,\n",
       " 0.769343313967302,\n",
       " 0.8049574705945615,\n",
       " 0.39255080053393326,\n",
       " 0.5222272925822802,\n",
       " 0.4748370502868549,\n",
       " 0.49758046214027213,\n",
       " 0.48225550222187513,\n",
       " 0.37712822940586493,\n",
       " 0.9042458260704725,\n",
       " 1.036600195114734,\n",
       " 1.1355908693702232,\n",
       " 1.0015766380159328,\n",
       " 1.077028707757891,\n",
       " 0.9859720828729027,\n",
       " 0.30960169977403806,\n",
       " 0.19098849954470354,\n",
       " -0.005058851303497258,\n",
       " -0.10960844490910904,\n",
       " -0.003203939158881619,\n",
       " 0.16407541061009745,\n",
       " 1.0923165616063235,\n",
       " 1.034624399790638,\n",
       " 0.9453306935499776,\n",
       " 0.8562380052947379,\n",
       " 0.948292864240797,\n",
       " 1.0173558170053631,\n",
       " 0.8200415368639666,\n",
       " 0.7983029224150717,\n",
       " 0.7082450674974037,\n",
       " 0.7498026998961578,\n",
       " 0.7920397567126538,\n",
       " 0.8660228452751815,\n",
       " 1.0662696309626842,\n",
       " 1.0845327649774854,\n",
       " 0.9622078947067412,\n",
       " 0.8736336011163768,\n",
       " 0.8570213934123082,\n",
       " 0.8970477777311773,\n",
       " 0.8239502586397661,\n",
       " 1.0183967828507443,\n",
       " 0.9011661666907919,\n",
       " 0.8777064001903402,\n",
       " 1.0855965352753358,\n",
       " 1.1912636495077606,\n",
       " 1.0665542771169103,\n",
       " 1.0841568618961541,\n",
       " 0.8917596631560718,\n",
       " 0.17750874040720016,\n",
       " 0.1389481204065507,\n",
       " 0.12149436609046727,\n",
       " 1.1241152967244112,\n",
       " 1.2290163237993164,\n",
       " 1.276691036210013,\n",
       " 1.1904767193578214,\n",
       " 1.289130332168075,\n",
       " 1.2749417602159108,\n",
       " 1.2336765410448098,\n",
       " 1.384413729513754,\n",
       " 1.5269021812823735,\n",
       " 1.7434032705676035,\n",
       " 2.184880178624698,\n",
       " 2.713025320231778,\n",
       " 1.0669473637679716,\n",
       " 1.2063676247941737,\n",
       " 1.1129640066748443,\n",
       " 1.1070185326393263,\n",
       " 1.0670799765717378,\n",
       " 1.0966084275436792,\n",
       " 1.0594413027764786,\n",
       " 1.1062119988094732,\n",
       " 1.0906501126748585,\n",
       " 1.1952463965304647,\n",
       " 1.2897232025171137,\n",
       " 1.3626854883285853,\n",
       " 1.1890346487497419,\n",
       " 1.327355956670951,\n",
       " 1.3701537231373582,\n",
       " 1.4430038397243772,\n",
       " 1.461384071717787,\n",
       " 1.6034619234040728,\n",
       " 1.286934454065036,\n",
       " 1.4494332163459596,\n",
       " 1.5500643613919662,\n",
       " 0.9532087179430759,\n",
       " 1.0144895646529435,\n",
       " 0.957242765302792,\n",
       " 1.030263050515492,\n",
       " 1.0113027393161231,\n",
       " 0.9499197519109925,\n",
       " 0.8114985990587853,\n",
       " 0.8020184434591007,\n",
       " 0.8405511275536572,\n",
       " 0.6468700582679185,\n",
       " 0.6164539199065435,\n",
       " 0.5313314717991824,\n",
       " 0.41764492185830515,\n",
       " 0.2766408331315089,\n",
       " 0.24084666562192814,\n",
       " 1.0195548469549154,\n",
       " 0.895785091548672,\n",
       " 1.152285869744018,\n",
       " 1.0892178820433005,\n",
       " 0.8953953611965226,\n",
       " 1.1529109567374003,\n",
       " 1.017419633251685,\n",
       " 1.018756799795778,\n",
       " 0.8523281892941583,\n",
       " 0.8202118801169411,\n",
       " 0.7374898952755474,\n",
       " 0.6958189233378107,\n",
       " 1.1073819741281152,\n",
       " 1.2436097908377328,\n",
       " 1.2016323692718238,\n",
       " 1.2775647043424287,\n",
       " 1.2106400976212561,\n",
       " 1.2162699278396512,\n",
       " 1.0133855214814542,\n",
       " 0.8707868576598152,\n",
       " 0.8282301307429163,\n",
       " 0.8964184828335633,\n",
       " 0.9394288668331834,\n",
       " 1.0519463735127565,\n",
       " 0.33329344183820014,\n",
       " 0.3750598372426999,\n",
       " 0.4826073081219084,\n",
       " 0.6247805967767672,\n",
       " 0.6208313387585767,\n",
       " 0.34673687569810113,\n",
       " 1.1271302509709256,\n",
       " 1.1788316374711538,\n",
       " 1.2049231077117433,\n",
       " 1.1539784488958658,\n",
       " 1.5253503774257502,\n",
       " 1.5322234660629523,\n",
       " 1.1211580854771883,\n",
       " 1.2670902438742888,\n",
       " 1.2880959800560923,\n",
       " 1.453256466188844,\n",
       " 1.5169661715314566,\n",
       " 1.6079140842306938,\n",
       " 1.0497788054692456,\n",
       " 1.036611508538671,\n",
       " 0.8745895255758684,\n",
       " 0.8501818532167547,\n",
       " 0.7917319009883501,\n",
       " 0.9497394641552457,\n",
       " 1.1657944161900942,\n",
       " 1.5331736552218962,\n",
       " 1.7167366577331333,\n",
       " 2.080085255449806,\n",
       " 2.343839027581404,\n",
       " 2.99763648257961,\n",
       " 1.103356316621535,\n",
       " 1.0683824565248017,\n",
       " 1.1383790912079141,\n",
       " 1.1969786498035595,\n",
       " 0.5714601562133141,\n",
       " 0.6214996791209478,\n",
       " 0.49587321469434953,\n",
       " 0.5395756732157267,\n",
       " 0.524778777810851,\n",
       " 0.5603945609365403,\n",
       " 0.5994514825284798,\n",
       " 0.6015161656082298,\n",
       " 1.3844948471416365,\n",
       " 1.3931811381632322,\n",
       " 1.4870337981856263,\n",
       " 1.7320266881356248,\n",
       " 1.8650262655426313,\n",
       " 2.0690307197344757,\n",
       " 1.218332396607701,\n",
       " 1.184052101259075,\n",
       " 1.3225059438621294,\n",
       " 1.469929175816641,\n",
       " 1.5819229335542846,\n",
       " 1.8837880798283375,\n",
       " 0.9078472615039896,\n",
       " 0.9181718829803007,\n",
       " 0.8676471395855871,\n",
       " 0.9283317498585857,\n",
       " 0.914931709219118,\n",
       " 1.0397607763236656,\n",
       " 1.2264172047384212,\n",
       " 1.2241598454420661,\n",
       " 0.9205145152270071,\n",
       " 0.9190604504550308,\n",
       " 0.7440337587065939,\n",
       " 1.0444964156794956,\n",
       " 0.786641279729206,\n",
       " 0.8737533200354138,\n",
       " 1.007280077654162,\n",
       " 1.058679737028306,\n",
       " 1.0621037735513625,\n",
       " 1.0431880162277287,\n",
       " 0.39255080053393326,\n",
       " 0.5222272925822802,\n",
       " 0.4748370502868549,\n",
       " 0.49758046214027213,\n",
       " 0.48225550222187513,\n",
       " 0.37712822940586493,\n",
       " 1.107897266858948,\n",
       " 1.3466968822963878,\n",
       " 1.9028704848235132,\n",
       " 3.1321659112759237,\n",
       " 3.0027606098063453,\n",
       " 3.567834088724076,\n",
       " 1.4011490407355707,\n",
       " 1.5894371315513203,\n",
       " 1.7955838072934092,\n",
       " 2.1208511669223937,\n",
       " 3.0687578592771194,\n",
       " 4.740871701987748,\n",
       " 1.0921705582009065,\n",
       " 1.1182376226263553,\n",
       " 1.1596222247719579,\n",
       " 1.2806852733635476,\n",
       " 1.4834848832539729,\n",
       " 1.659607882508175,\n",
       " 1.1157466195676435,\n",
       " 1.77590253888363,\n",
       " 1.7411939448510456,\n",
       " 1.8010681935369677,\n",
       " 1.7901399887639586,\n",
       " 1.980998776348902,\n",
       " 1.1691038071076922,\n",
       " 1.241933747108812,\n",
       " 1.479603395772943,\n",
       " 2.2365325557455495,\n",
       " 2.6996222611781833,\n",
       " 3.030313863488549,\n",
       " 1.3092344162612535,\n",
       " 1.0069563729606457,\n",
       " 0.7629182547383255,\n",
       " 0.9385587926077844,\n",
       " 1.432787704554511,\n",
       " 0.8288011850597821,\n",
       " 1.0324327778754134,\n",
       " 1.0444153312776598,\n",
       " 1.1893243437554921,\n",
       " 1.3717786902270295,\n",
       " 1.3407838187598855,\n",
       " 1.4165135562620823,\n",
       " 1.1926422120446862,\n",
       " 1.3209990155373883,\n",
       " 1.3062620382656338,\n",
       " 1.3734366305697043,\n",
       " 1.2534905619997432,\n",
       " 1.243864229765013,\n",
       " 0.951745870070344,\n",
       " 0.8746220199255182,\n",
       " 0.7662730368908551,\n",
       " 0.9947480663335136,\n",
       " 1.0914154756978705,\n",
       " 1.1130279784829873,\n",
       " 1.0814550038696913,\n",
       " 1.2419793669664014,\n",
       " 1.369256301213567,\n",
       " 1.5233657536323237,\n",
       " 1.6032250085771502,\n",
       " 1.6782651017688877,\n",
       " 1.0144834245252654,\n",
       " 1.1119294193377387,\n",
       " 1.137431606050853,\n",
       " 1.2125939529336036,\n",
       " 1.254529620023098,\n",
       " 1.6085120884530189,\n",
       " 0.69902450630502,\n",
       " 0.8099728264272386,\n",
       " 0.8440337102570843,\n",
       " 0.8499192306247416,\n",
       " 0.9364489024130633,\n",
       " 1.0490877443430129,\n",
       " 1.2667910859818452,\n",
       " 1.4969686595843363,\n",
       " 1.6161185590918126,\n",
       " 1.6736588113170043,\n",
       " 1.7881816374759811,\n",
       " 2.240767939571968,\n",
       " 1.0844669214805913,\n",
       " 1.2295105681015248,\n",
       " 1.3537963380234672,\n",
       " 1.375867229705295,\n",
       " 1.4951958117047495,\n",
       " 1.4742543354530735,\n",
       " 1.242528185215644,\n",
       " 1.1954227001592737,\n",
       " 0.940376427478373,\n",
       " 0.8231332174347548,\n",
       " 0.7998407262052236,\n",
       " 0.769651575561362,\n",
       " 0.46058484995566007,\n",
       " 0.7950142143428011,\n",
       " 0.7166984771129009,\n",
       " 0.7533017783438375,\n",
       " 0.5583882869436062,\n",
       " 0.49331980629080474,\n",
       " 1.0272121625881827,\n",
       " 1.097432653342436,\n",
       " 1.1864912093900124,\n",
       " 1.2997513450541465,\n",
       " 1.4355010783398783,\n",
       " 1.53943091213148,\n",
       " 1.2114988331098864,\n",
       " 1.2137100278067432,\n",
       " 0.9484442499627589,\n",
       " 0.9367287973583595,\n",
       " 0.936767590247778,\n",
       " 0.940646879189632,\n",
       " 1.1387249114521842,\n",
       " 1.3226596020387595,\n",
       " 1.5565554179744874,\n",
       " 1.658133440838541,\n",
       " 1.5388170587727132,\n",
       " 1.830780084660351,\n",
       " 0.4844975421087525,\n",
       " 0.25164019883198585,\n",
       " 0.3118427169670145,\n",
       " 0.4068133240537738,\n",
       " 0.5358808108427803,\n",
       " 0.3824407258962982,\n",
       " 1.5205069393150097,\n",
       " 1.7383713019476734,\n",
       " 1.6770157057885937,\n",
       " 1.6640555145200793,\n",
       " 1.7302511371146445,\n",
       " 1.9677185787038831,\n",
       " 1.203799032224853,\n",
       " 1.2537321116030062,\n",
       " 1.434194721850441,\n",
       " 1.7321802395415076,\n",
       " 1.7646453207042105,\n",
       " 2.1242836061635604,\n",
       " 1.260850215108708,\n",
       " 1.682496250020604,\n",
       " 1.9350223350421147,\n",
       " 2.311833451464552,\n",
       " 2.5514200471425976,\n",
       " 3.181499002752731,\n",
       " 1.0906578470460313,\n",
       " 1.3978343602754624,\n",
       " 1.5826839434577749,\n",
       " 1.7683943457774558,\n",
       " 1.8313700616165276,\n",
       " 2.142624139180863,\n",
       " 0.8145082533406379,\n",
       " 0.7938570373722699,\n",
       " 0.6322201843603362,\n",
       " 0.6375199485506039,\n",
       " 0.6413548340995167,\n",
       " 1.0501750708620157,\n",
       " 0.955497081176012,\n",
       " 1.0241928619110268,\n",
       " 1.0885578216866605,\n",
       " 1.103193009756294,\n",
       " 1.133956772433279,\n",
       " 1.2337149931528224,\n",
       " 1.0787651211061802,\n",
       " 1.0595270325944934,\n",
       " 1.0374363863940455,\n",
       " 1.1722952691488233,\n",
       " 1.3679720943737517,\n",
       " 1.559960605668232,\n",
       " 0.9917262406938709,\n",
       " 1.0086931209883123,\n",
       " 0.8521947416978721,\n",
       " 0.961986096926819,\n",
       " 1.0979998914593294,\n",
       " 1.3878528188505543,\n",
       " 1.2546744328354822,\n",
       " 1.469437708224735,\n",
       " 1.6143961199374472,\n",
       " 2.020850803435849,\n",
       " 3.0132810552319644,\n",
       " 3.0972961947283726,\n",
       " 1.006800714946956,\n",
       " 1.189260922302088,\n",
       " 1.3667462476824488,\n",
       " 1.5426519198172115,\n",
       " 1.7342977082206077,\n",
       " 1.9484612484902257,\n",
       " 1.0254673584219207,\n",
       " 1.1141296492880601,\n",
       " 1.029454420405783,\n",
       " 0.926937089145722,\n",
       " 0.9285817522140651,\n",
       " 0.9699475202966372,\n",
       " 0.9358437935843793,\n",
       " 1.0365511955470117,\n",
       " 1.076004875168055,\n",
       " 1.0611783331448603,\n",
       " 1.0384359254652145,\n",
       " 1.080465402641135,\n",
       " 0.8090430141546419,\n",
       " 1.1382725559514146,\n",
       " 1.1940566093969947,\n",
       " 1.3349794351898978,\n",
       " 1.3030661512854727,\n",
       " 1.2371945655712524,\n",
       " 0.45373774852199933,\n",
       " -0.005811419439198495,\n",
       " -0.2894533912985171,\n",
       " 0.7637546239899855,\n",
       " 1.6645246370656794,\n",
       " 1.5591367806971466,\n",
       " 1.2608834136971265,\n",
       " 1.5755468658120666,\n",
       " 1.5482966796032773,\n",
       " 1.4652573601473988,\n",
       " 1.4423585793249445,\n",
       " 1.3350925163667724,\n",
       " 1.147712326532635,\n",
       " 1.3171585317759384,\n",
       " 1.3800249012518764,\n",
       " 1.5298350446921725,\n",
       " 1.4805549303859282,\n",
       " 1.4435685187058782,\n",
       " 1.2153250863616183,\n",
       " 1.3235907134724125,\n",
       " 1.320044579964104,\n",
       " 1.259012486249686,\n",
       " 1.2376633151282395,\n",
       " 1.3273298338383155,\n",
       " 1.0344811329307877,\n",
       " 0.9758218644037064,\n",
       " 1.0158914939527464,\n",
       " 1.0617708389998006,\n",
       " 1.1445393388819383,\n",
       " 1.2335019673974146,\n",
       " 0.3881917968158788,\n",
       " 0.4654260750072673,\n",
       " 0.45236670966935977,\n",
       " 0.4389277674875617,\n",
       " 0.49259224558141324,\n",
       " 0.5492621074202468,\n",
       " 1.0900623846762147,\n",
       " 1.0951669658285947,\n",
       " 1.018598248542893,\n",
       " 0.6033280195480353,\n",
       " 0.2713210404977385,\n",
       " 0.2792707980301337,\n",
       " 1.2636695414159407,\n",
       " 1.4428887971672497,\n",
       " 1.5213651076401713,\n",
       " 1.7558436339148003,\n",
       " 2.1680479221428106,\n",
       " 2.552418916863989,\n",
       " 1.0929978269213247,\n",
       " 1.2611560115860714,\n",
       " 1.3063847647027964,\n",
       " 1.224818380876908,\n",
       " 1.6081859072948623,\n",
       " 1.7065404974058358,\n",
       " 1.2030598198993367,\n",
       " 1.3682921959881893,\n",
       " 1.4468366800113481,\n",
       " 1.4699534512288663,\n",
       " 1.5324738097489727,\n",
       " 1.6617175761014615,\n",
       " 1.050312904915502,\n",
       " 1.204525404570893,\n",
       " 0.2964808535274171,\n",
       " 0.18879056047197634,\n",
       " 0.15398505775645793,\n",
       " 0.2166177321975023,\n",
       " 0.6059263178781666,\n",
       " 0.734969243997619,\n",
       " 0.7966796745816525,\n",
       " 0.34770818175805296,\n",
       " 0.40511938620279153,\n",
       " 0.3713208545538724,\n",
       " 1.0034053785428567,\n",
       " 0.9678647950662749,\n",
       " 0.916010167254597,\n",
       " 0.7752531630100941,\n",
       " 0.7337450202448943,\n",
       " 0.7609758283298169,\n",
       " 0.513983145648445,\n",
       " 0.523678126631367,\n",
       " 0.4524573047952868,\n",
       " 0.33190394511149224,\n",
       " 0.21299127451711541,\n",
       " 0.1654112909240062,\n",
       " 0.9365379259121718,\n",
       " 1.0116980781728717,\n",
       " 1.217055055240925,\n",
       " 1.2200399220128124,\n",
       " 1.315908457896203,\n",
       " 1.346532355398756,\n",
       " 1.2755957867319663,\n",
       " 1.2266213607370013,\n",
       " 0.9839274004576453,\n",
       " 0.9425880324478504,\n",
       " 0.8832501043228647,\n",
       " 0.8877210842240904,\n",
       " 1.0986522425963328,\n",
       " 1.253954288228119,\n",
       " 1.2847187506248876,\n",
       " 1.3362094822931874,\n",
       " 1.2684216840968627,\n",
       " 1.2763202623527765,\n",
       " 0.9808409982237386,\n",
       " 0.8628497564235592,\n",
       " 0.8756634600165315,\n",
       " 0.9487856351453544,\n",
       " 0.9860871247427939,\n",
       " 1.088241501204692,\n",
       " 0.29659664795003465,\n",
       " 0.3260129808393774,\n",
       " 0.3826335383847845,\n",
       " 0.5296210705662525,\n",
       " 0.45403286157379735,\n",
       " 0.2250090602305299,\n",
       " 1.1478466150214268,\n",
       " 1.1828906103968932,\n",
       " 1.2576862101670512,\n",
       " 1.1876882178238388,\n",
       " 1.5966963661412146,\n",
       " 1.6453439669913537,\n",
       " 1.1481751598286887,\n",
       " 1.3281867461154908,\n",
       " 1.432359878343989,\n",
       " 1.546153766577701,\n",
       " 1.6279301926220182,\n",
       " 1.7667587362671473,\n",
       " 1.127192720317963,\n",
       " 1.277732122045244,\n",
       " 1.2885649822191674,\n",
       " 1.1608119415473808,\n",
       " 1.0666781221050115,\n",
       " 1.0569659026387352,\n",
       " 1.077293279066889,\n",
       " 1.2124545858300508,\n",
       " 1.262954414730573,\n",
       " 1.4473268436878854,\n",
       " 1.978936562138234,\n",
       " 2.332340713666844,\n",
       " 1.425793433781516,\n",
       " 1.5197005412132985,\n",
       " 1.6450809934186954,\n",
       " 1.9218993380980218,\n",
       " 2.1246563201267232,\n",
       " 3.922050198947746,\n",
       " 1.0475619745115516,\n",
       " 1.1974300754053335,\n",
       " 1.4358181358259652,\n",
       " 1.7508913729552626,\n",
       " 2.0107958515020834,\n",
       " 2.104992290828495,\n",
       " 0.9189097680717793,\n",
       " 0.9955137971897747,\n",
       " 0.9935669544608092,\n",
       " 0.9199255121042831,\n",
       " 0.8308786185881158,\n",
       " 0.8997799221262908,\n",
       " 0.8968500578809482,\n",
       " 1.4189971364162552,\n",
       " 1.7767623225491986,\n",
       " 1.8950425475740769,\n",
       " 1.7468876297244051,\n",
       " 2.0059302585349013,\n",
       " 1.0996371771043172,\n",
       " 1.4210526315789471,\n",
       " 1.573939076916228,\n",
       " 1.6710888025731492,\n",
       " 1.607244215423312,\n",
       " 1.74309690487585,\n",
       " 0.9707919156317975,\n",
       " 1.0655822342153811,\n",
       " 1.0960087562298646,\n",
       " 1.073429798716854,\n",
       " 1.0414199961450556,\n",
       " 1.0715711650191369,\n",
       " 0.7941668447080035,\n",
       " 0.8525296634237087,\n",
       " 0.6774412072765927,\n",
       " 0.5054793307035323,\n",
       " 0.3314330677477684,\n",
       " 0.2840132775412577,\n",
       " 0.4700249376558603,\n",
       " 0.8873815461346634,\n",
       " 0.7291271820448878,\n",
       " 0.6170074812967581,\n",
       " 0.26735660847880305,\n",
       " 0.35306733167082294,\n",
       " 0.806771402167521,\n",
       " 1.4452658993531045,\n",
       " 1.4553473914139294,\n",
       " 1.7124254389649667,\n",
       " 1.7762748886835253,\n",
       " 2.3038729732000336,\n",
       " 0.9112776025236593,\n",
       " 1.5670347003154574,\n",
       " 1.4250788643533123,\n",
       " 1.985410094637224,\n",
       " 1.7618296529968454,\n",
       " 2.0646687697160884,\n",
       " 0.9682311080989495,\n",
       " 0.9440020332090818,\n",
       " 0.7278888512368688,\n",
       " 0.5843781768891901,\n",
       " 0.8357336496103015,\n",
       " 1.2031514740765838,\n",
       " 0.43884417134296516,\n",
       " 0.4896275042531041,\n",
       " 0.3601300053322499,\n",
       " 0.3169641723586319,\n",
       " 0.34235583881370135,\n",
       " 0.3728258385597847,\n",
       " 0.8879989988737329,\n",
       " 0.9449693405080717,\n",
       " 0.9208797397071706,\n",
       " 0.9274496308346891,\n",
       " 0.9268239269177827,\n",
       " 1.1589600800901017,\n",
       " 0.9667599010904375,\n",
       " 0.9349791235964167,\n",
       " 0.7328428391908877,\n",
       " 0.8061534719688681,\n",
       " 0.8418663099436541,\n",
       " 1.0248895374761848,\n",
       " 1.402792203824769,\n",
       " 1.9372212378566631,\n",
       " 1.577198020406917,\n",
       " 1.3989124457750355,\n",
       " 1.2578969878413881,\n",
       " 1.2596688458483534,\n",
       " 0.10674643847480117,\n",
       " 0.18459545999888763,\n",
       " 0.12368602960455746,\n",
       " 0.11001199755281701,\n",
       " 0.12204133196672465,\n",
       " 0.17590319325594508,\n",
       " 0.8930027520130466,\n",
       " 2.185251248598512,\n",
       " 1.078355927020691,\n",
       " 1.0039241667516055,\n",
       " 1.9229691162980327,\n",
       " 2.060875547854449,\n",
       " 0.00393605912121453,\n",
       " 0.13611169936979234,\n",
       " -0.1136345380059735,\n",
       " -0.315184133081153,\n",
       " 0.10105959587845681,\n",
       " -0.0347673051504685,\n",
       " 1.1780406112622983,\n",
       " 1.3840537994557252,\n",
       " -0.11815731630730586,\n",
       " 1.2038020724303957,\n",
       " 0.8957112204312327,\n",
       " 1.249986916474775,\n",
       " 0.4440713907050715,\n",
       " -1.1933203746244918,\n",
       " 0.4765859692525183,\n",
       " 0.48595158155151097,\n",
       " -0.771426047004771,\n",
       " 0.21169817989044004,\n",
       " 1.1637696455959234,\n",
       " 1.101926216666392,\n",
       " 1.0227666276365917,\n",
       " 1.0557497897323418,\n",
       " 1.0161699952174417,\n",
       " 1.2874565034549865,\n",
       " 1.0326219802889909,\n",
       " 0.6492801234321774,\n",
       " 0.36843724808654127,\n",
       " 0.23820069863999238,\n",
       " 0.3979084140178734,\n",
       " 0.45620064663205256,\n",
       " 1.3710652621080843,\n",
       " 1.6591036589166615,\n",
       " 1.9814560867668138,\n",
       " 1.8787321573271831,\n",
       " 1.8700367761640586,\n",
       " 0.6762139250763572,\n",
       " 1.5262152731296796,\n",
       " 1.8119729056785627,\n",
       " 2.000080319134695,\n",
       " 2.22621438069485,\n",
       " 2.548731403889231,\n",
       " 2.7912327202306053,\n",
       " 0.18261739959772988,\n",
       " 0.015854729506416476,\n",
       " -0.17508191767627646,\n",
       " -0.0498682707107716,\n",
       " -0.011152135525359097,\n",
       " -0.169227282599458,\n",
       " 0.9551972635979593,\n",
       " 0.9686453932847057,\n",
       " 0.9722851588194883,\n",
       " 1.2955811199953224,\n",
       " 1.400286503632457,\n",
       " 0.5612693865021707,\n",
       " 0.845246007652374,\n",
       " 0.9058123312196497,\n",
       " 0.4088331626818038,\n",
       " 0.6801092169789292,\n",
       " 0.5700000598777297,\n",
       " 1.0946547150718238,\n",
       " 0.449525875642955,\n",
       " 0.6796132358258395,\n",
       " -2.105753641951548,\n",
       " 0.21277861366737838,\n",
       " 0.16179712376220357,\n",
       " 0.79543254370925,\n",
       " 1.2475958651282337,\n",
       " 1.3050148531896322,\n",
       " 1.403614409595721,\n",
       " 1.2390923139748096,\n",
       " 1.028321149180472,\n",
       " 1.4712104348661608,\n",
       " 1.175954171809142,\n",
       " 1.5602775772535682,\n",
       " 2.7703001653354433,\n",
       " 4.181100528607688,\n",
       " -1.8874088908553195,\n",
       " 2.490487390261509,\n",
       " 0.8675694285058528,\n",
       " 0.458972213790193,\n",
       " 0.39460415941717814,\n",
       " 0.7122613221586325,\n",
       " 0.428054224940215,\n",
       " 0.6927598895363043,\n",
       " 1.0964730290456433,\n",
       " 1.196058091286307,\n",
       " 0.6991701244813278,\n",
       " 1.545643153526971,\n",
       " 1.5726141078838174,\n",
       " 1.9522821576763485,\n",
       " 0.7079658803790507,\n",
       " 0.8179534367950818,\n",
       " 0.8405288794092098,\n",
       " 0.5988813416675849,\n",
       " 0.59201840711289,\n",
       " 0.4932282702334662,\n",
       " 0.6677714954182103,\n",
       " 0.5074088516279978,\n",
       " 0.25726262429323454,\n",
       " 0.5686293624488205,\n",
       " 0.6180542015987522,\n",
       " 0.4720218366153246,\n",
       " 1.3012007668763241,\n",
       " 1.2712993172109917,\n",
       " 1.180888634758333,\n",
       " 1.7861827721906425,\n",
       " 2.2946083212808173,\n",
       " 3.085836332447613,\n",
       " 1.0837925851703405,\n",
       " 0.8061122244488977,\n",
       " 0.691382765531062,\n",
       " 0.3852705410821643,\n",
       " 0.12236973947895792,\n",
       " 0.6880010020040079,\n",
       " 1.1463948129052417,\n",
       " 0.8268104054370751,\n",
       " 0.27060385907350987,\n",
       " 0.4694164518397,\n",
       " 0.6457308022810717,\n",
       " 0.9623466916647136,\n",
       " 0.9437609841827769,\n",
       " 0.6915641476274166,\n",
       " 0.15289982425307558,\n",
       " 0.3646748681898067,\n",
       " 0.39015817223198596,\n",
       " 0.5852372583479789,\n",
       " -0.3739900858617089,\n",
       " -0.1707401137388871,\n",
       " -1.0188145610104713,\n",
       " 0.3773758958711362,\n",
       " 0.37646355185661995,\n",
       " 0.08674364146907676,\n",
       " 1.1752810806438565,\n",
       " 1.3985091992857097,\n",
       " 1.680784474766518,\n",
       " 1.9791561669746573,\n",
       " 2.344234346903602,\n",
       " 2.4742563107037747,\n",
       " 1.107602001539646,\n",
       " 1.2280985373364126,\n",
       " 1.1551963048498846,\n",
       " 1.2880677444187836,\n",
       " 1.392571208622017,\n",
       " 1.567859892224788,\n",
       " 0.9287024214978105,\n",
       " 0.7139488753321607,\n",
       " -0.6273438377184772,\n",
       " 0.3776713200344325,\n",
       " 0.5787641753059621,\n",
       " 0.9083049515326173,\n",
       " 0.9473198557168022,\n",
       " 0.8590722254844393,\n",
       " 0.8235047395352738,\n",
       " 0.6886167267846657,\n",
       " 0.6984313396527136,\n",
       " 0.7615132958644409,\n",
       " 1.3908771929824564,\n",
       " 1.5070175438596491,\n",
       " -2.2582456140350873,\n",
       " 0.6571929824561407,\n",
       " 0.16631578947368464,\n",
       " -1.6308771929824557,\n",
       " 0.729475472499469,\n",
       " 0.6813123805478869,\n",
       " 0.6798683372265877,\n",
       " 0.6806540666808238,\n",
       " 0.7179231259290717,\n",
       " 0.6692503716287959,\n",
       " 0.562351900413889,\n",
       " 0.6024138257874949,\n",
       " 0.6326498372879213,\n",
       " 0.6223184101608165,\n",
       " 0.5800132697229156,\n",
       " 0.6338188366876244,\n",
       " 0.18636476735506324,\n",
       " 0.25678029360537424,\n",
       " 0.329932819109231,\n",
       " 1.027867628763374,\n",
       " 0.8260761383428714,\n",
       " 1.1532719581985567,\n",
       " 0.5683453237410072,\n",
       " 0.21074904782056708,\n",
       " 0.06792213288192975,\n",
       " 0.4763013118916632,\n",
       " 1.1404993652137114,\n",
       " 1.6758358019466781,\n",
       " 1.2530651805185364,\n",
       " 1.197916161860916,\n",
       " 1.989677732008723,\n",
       " 2.480591228495275,\n",
       " 2.4873273564332448,\n",
       " 2.7716501090380423,\n",
       " 1.0766599930559837,\n",
       " 1.0948150263320993,\n",
       " 1.0347525301853795,\n",
       " 0.9437453557834895,\n",
       " 0.9776347512322384,\n",
       " 1.0578348946553788,\n",
       " 1.0286579212916247,\n",
       " 0.8387487386478307,\n",
       " 0.9477295660948539,\n",
       " 1.0096871846619577,\n",
       " 0.877699293642785,\n",
       " 0.8401614530776995,\n",
       " 1.0473022912047303,\n",
       " 1.123059866962306,\n",
       " 0.975240206947524,\n",
       " 1.084257206208426,\n",
       " 1.0587583148558757,\n",
       " 1.2376201034737622,\n",
       " 0.9182237854473512,\n",
       " 1.1013409540558365,\n",
       " 0.6821279402066389,\n",
       " 1.1367333479885688,\n",
       " 1.4537260936469554,\n",
       " 1.8313915146185977,\n",
       " 1.2765899533187257,\n",
       " 1.4595723831947414,\n",
       " 1.6381997087523987,\n",
       " 1.9244389400764867,\n",
       " 2.3473876178940354,\n",
       " 3.1930127795092345,\n",
       " 0.7314894932014834,\n",
       " 0.7301452410383188,\n",
       " 0.9307169344870209,\n",
       " 1.023702101359703,\n",
       " 1.7783992583436343,\n",
       " 2.1432632880098885]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chain(*normalized_test_data_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Year', 'MICRO', 'start', 1547921919.684053)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration with suspicious time 0.0554 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 0.0801 sec ignored in overall statistics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Year', 'INDUSTRY', 'start', 1547924236.744546)\n",
      "('Year', 'MACRO', 'start', 1547926028.698266)\n",
      "('Year', 'FINANCE', 'start', 1547927269.8709)\n",
      "('Year', 'DEMOGRAPHIC', 'start', 1547928184.157864)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6a9312eb3a29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mmyopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             model = catboost.CatBoostRegressor(**{el['name']: \n\u001b[1;32m     31\u001b[0m                                                   \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_opt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'continuous'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4f9e3e3dc7f0>\u001b[0m in \u001b[0;36mfind_parameters\u001b[0;34m(train_data)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmyBopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPyOpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmyBopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmyBopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/GPyOpt/core/bo.pyc\u001b[0m in \u001b[0;36mrun_optimization\u001b[0;34m(self, max_iter, max_time, eps, context, verbosity, save_models_parameters, report_file, evaluations_file, models_file)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# --- Evaluate *f* in X, augment Y and update cost function (if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# --- Update current evaluation time and function evaluations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/GPyOpt/core/bo.pyc\u001b[0m in \u001b[0;36mevaluate_objective\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mEvaluates\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggested_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_cost_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggested_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/GPyOpt/core/task/objective.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_procs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/GPyOpt/core/task/objective.pyc\u001b[0m in \u001b[0;36m_eval_func\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mst_time\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mrlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mf_evals\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mcost_evals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4f9e3e3dc7f0>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         )\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_series_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-3592b68658d0>\u001b[0m in \u001b[0;36mtime_series_cross_validation\u001b[0;34m(model, train_data)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mvalidation_forecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-3592b68658d0>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, fit_data)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Silent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/catboost/core.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2543\u001b[0;31m                          save_snapshot, snapshot_file, snapshot_interval)\n\u001b[0m\u001b[1;32m   2544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/catboost/core.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_leaf_weights_in_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/catboost/core.pyc\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfa = load_data('data/M3C.xls', frequency='Other', categories=['MICRO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(dfa.iterrows())[1].iloc[6:]\n",
    "test.index = range(104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>N</th>\n",
       "      <th>NF</th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_strength</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.023457</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3791.093479</td>\n",
       "      <td>3791.093479</td>\n",
       "      <td>3791.093479</td>\n",
       "      <td>3791.093479</td>\n",
       "      <td>3791.093479</td>\n",
       "      <td>3791.093479</td>\n",
       "      <td>3791.093479</td>\n",
       "      <td>3791.093479</td>\n",
       "      <td>3791.093479</td>\n",
       "      <td>3791.093479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>7.004325</td>\n",
       "      <td>61.730110</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>2</td>\n",
       "      <td>67.476996</td>\n",
       "      <td>...</td>\n",
       "      <td>5831.351873</td>\n",
       "      <td>5831.351873</td>\n",
       "      <td>5831.351873</td>\n",
       "      <td>5831.351873</td>\n",
       "      <td>5831.351873</td>\n",
       "      <td>5831.351873</td>\n",
       "      <td>5831.351873</td>\n",
       "      <td>5831.351873</td>\n",
       "      <td>5831.351873</td>\n",
       "      <td>5831.351873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "      <td>0.529419</td>\n",
       "      <td>0.614132</td>\n",
       "      <td>72.397338</td>\n",
       "      <td>7.062543</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>10</td>\n",
       "      <td>89.441656</td>\n",
       "      <td>...</td>\n",
       "      <td>4238.405943</td>\n",
       "      <td>4238.405943</td>\n",
       "      <td>4238.405943</td>\n",
       "      <td>4238.405943</td>\n",
       "      <td>4238.405943</td>\n",
       "      <td>4238.405943</td>\n",
       "      <td>4238.405943</td>\n",
       "      <td>4238.405943</td>\n",
       "      <td>4238.405943</td>\n",
       "      <td>4238.405943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "      <td>0.905362</td>\n",
       "      <td>0.547180</td>\n",
       "      <td>38.269129</td>\n",
       "      <td>47.912849</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>2</td>\n",
       "      <td>91.253371</td>\n",
       "      <td>...</td>\n",
       "      <td>7305.342997</td>\n",
       "      <td>7305.342997</td>\n",
       "      <td>7305.342997</td>\n",
       "      <td>7305.342997</td>\n",
       "      <td>7305.342997</td>\n",
       "      <td>7305.342997</td>\n",
       "      <td>7305.342997</td>\n",
       "      <td>7305.342997</td>\n",
       "      <td>7305.342997</td>\n",
       "      <td>7305.342997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   series    N  NF  colsample_bylevel  learning_rate  random_strength  \\\n",
       "0       0  105   8           1.000000       0.010000         0.000000   \n",
       "1       1  105   8           1.000000       0.010000         7.004325   \n",
       "2       2  105   8           0.529419       0.614132        72.397338   \n",
       "3       3  105   8           0.905362       0.547180        38.269129   \n",
       "\n",
       "   reg_lambda loss_function  max_depth  bagging_temperature     ...       \\\n",
       "0   88.023457          RMSE          2           100.000000     ...        \n",
       "1   61.730110          RMSE          2            67.476996     ...        \n",
       "2    7.062543          RMSE         10            89.441656     ...        \n",
       "3   47.912849          RMSE          2            91.253371     ...        \n",
       "\n",
       "            96           97           98           99          100  \\\n",
       "0  3791.093479  3791.093479  3791.093479  3791.093479  3791.093479   \n",
       "1  5831.351873  5831.351873  5831.351873  5831.351873  5831.351873   \n",
       "2  4238.405943  4238.405943  4238.405943  4238.405943  4238.405943   \n",
       "3  7305.342997  7305.342997  7305.342997  7305.342997  7305.342997   \n",
       "\n",
       "           101          102          103          104          105  \n",
       "0  3791.093479  3791.093479  3791.093479  3791.093479  3791.093479  \n",
       "1  5831.351873  5831.351873  5831.351873  5831.351873  5831.351873  \n",
       "2  4238.405943  4238.405943  4238.405943  4238.405943  4238.405943  \n",
       "3  7305.342997  7305.342997  7305.342997  7305.342997  7305.342997  \n",
       "\n",
       "[4 rows x 118 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Quart', 'MICRO', 'start', 1547844994.548564),\n",
       " ('Quart', 'MICRO', 'stop', 1547848365.044193),\n",
       " ('Quart', 'INDUSTRY', 'start', 1547848365.103962),\n",
       " ('Quart', 'INDUSTRY', 'stop', 1547849836.472323),\n",
       " ('Quart', 'MACRO', 'start', 1547849836.513376),\n",
       " ('Quart', 'MACRO', 'stop', 1547855517.940709),\n",
       " ('Quart', 'FINANCE', 'start', 1547855518.022607),\n",
       " ('Quart', 'FINANCE', 'stop', 1547856814.215862),\n",
       " ('Quart', 'DEMOGRAPHIC', 'start', 1547856814.25633),\n",
       " ('Quart', 'DEMOGRAPHIC', 'stop', 1547857823.435118),\n",
       " ('Quart', 'OTHER', 'start', 1547857823.47109),\n",
       " ('Quart', 'OTHER', 'stop', 1547857824.022123)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
